#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Oct 20 20:10:44 2022
Tools to deal with sorting nodes of the graph in a clinical flow
@author: rafael
"""
import networkx as nx
import pandas as pd
import cleanhtml as ch
from sympy import And, Or, S, simplify
from itertools import combinations
import re
import base64, os

import warnings
warnings.filterwarnings("ignore")

def longest_path_lengths(dag, rootelement, df_raw):
    dist = dict.fromkeys(dag.nodes, -float('inf')) # keys are nodes, values their longest path length from source   
    dist[rootelement] = 0 # set path length of source to 0   
    opt_prio = hierarchy_select_options(df_raw) # hierarchy for select_options
    topo_order = nx.topological_sort(dag) # topological sort for iterating over nodes   
    for n in topo_order:
        for s in dag.successors(n):
            if dist[s] < dist[n] + 1:
                if s in opt_prio:
                    dist[s] = opt_prio[s] + dist[n] + 1
                else:
                    dist[s] = dist[n] + 1   
    return dist


def hierarchy_diagnosis(dag, diagnosis_id_hierarchy):
    '''Makes a dictionary that maps the diagnosis select_options to a sorting value. 
    This dictionary has the same shape as the one generated by the function 'hierarchy_select_option'. 
    However, that function cannot be used because the select_diagnosis node and the successor select_option 
    nodes do not exist in df_raw. They have been directly added to the graph
    '''
    # making a dict that maps the diagnosis ids to the corresponding select_options of the select_diagnosis:
    # select_options of the diagnosis selector (they are direct predecessors of the diagnosis calculates)
    select_diagnosis_options = [n for n in dag.successors('select_diagnosis')]

    # select_diagnosis_successors (these are the diagnosis calculates themselves)
    option_successors = [list(dag.successors(n))[0] for n in select_diagnosis_options]

    d = dict(zip(option_successors, select_diagnosis_options)) # map diagnosis_id to the select-option-id
    select_diagnosis_options_id_hierarchy = [d[i] for i in diagnosis_id_hierarchy]

    # {diagnosis_node_id: sorting-value} 
    # the higher the sorting value, the earlier the TT for this diagnosis is displayed
    d = {i[1]:i[0]/1000+0.001 for i in enumerate(reversed(select_diagnosis_options_id_hierarchy))} 
    
    return d


def hierarchy_select_options(df_raw):
    '''
    add function description here
    '''
    
    opt_prio = {}    
    df_options = df_raw[df_raw['odk_type']=='select_option'] #subframe with select_option only
    g = df_options.groupby(['parent']) # group options by select question
    for quest, frame in g: # iterate over select_questions
        frame['y'] = pd.to_numeric(frame['y']) # convert the string value into a numeric one
        frame.sort_values('y', ascending = False, inplace=True) # reverse sort select_options by y value
        frame.reset_index(drop=True, inplace=True) # reset index to have the proper sorting
        q_dict = dict(zip(frame['id'], frame.index/100+0.01)) # make a dict for that select options, divide index by 100, offset by 0.01
        opt_prio.update(q_dict) # update global option-nodes dictionnary
    return opt_prio
   
def topo_sort_cdss_dag(dag, df_raw):
    rootelements = [n for n,d in dag.in_degree() if d==0]  # elements that are origins
    rootelement = df_raw[df_raw['id'].isin(rootelements) & ~df_raw['style'].str.contains('image',na=False)]['id'].iloc[0]
    dist = longest_path_lengths(dag, rootelement, df_raw) # dictionnary with the distance from root for each node, select_options hierarchy included
    
    # I need to take the reciprocal values in'dist' because the sorting takes smaller numbers first
     
    # lexicographical topological sort that respects the sort behaviour described by 'node_sort_value'
    dist[rootelement] = 0.001 # avoid division by 0
    topo_order = list(nx.lexicographical_topological_sort(dag, key = lambda x: 1/dist[x]))
    
    df_raw_sorted = df_raw.set_index('id') # set id to index in order to be able to sort df_raw
    df_raw_sorted = df_raw_sorted.reindex(topo_order) # sort elements in df_raw
    df_raw_sorted.reset_index(inplace = True)
    
    return df_raw_sorted, topo_order


def get_graph_entry_point(dag):
    '''
    A split-off of the function 'topo_sort_cdss_dag'. It provides one possible entry point into the graph. 
    Typically this is an element pointing to the dataloader. 
    @param: dag The graph, it should be complete and have only 1 entry point (root-node)
    @param: df_raw The dataframe read out from xml, it is the pure data containing all objects in the file
    @result: rootelement is the ID of the first rootelement
    '''
    rootelements = [n for n,d in dag.in_degree() if d==0]  # elements that are origins
    rootelement = rootelements[0]
    return rootelement


def get_topo_sort_cdss(dag, rootelement, opt_prio):
    '''Split of the function 'topo_sort_cdss_dag'. It does not derive the rootelement, but takes it as input. It provides just the proper CDSS sorting of the elements
    @param: dag The graph, it should be complete and have only 1 entry point (root-node)
    @param: rootelement The entry node to the graph, there should be only 1 at this stage
    @param: df_raw The dataframe read out from xml, it is the pure data containing all objects in the file
    @result: topo_order The right sorting of all nodes of the graph   
    '''
    dist = get_longest_path_lengths(dag, rootelement, opt_prio) # dictionnary with the distance from root for each node, select_options hierarchy included
    # I need to take the reciprocal values in'dist' because the sorting takes smaller numbers first
    
    # lexicographical topological sort that respects the sort behaviour described by 'node_sort_value'
    # dist[rootelement] = 0.001 # avoid division by 0
    
    topo_order = list(nx.lexicographical_topological_sort(dag, key = lambda x: 1/dist[x]))
    
    return topo_order

def topo_sort_cdss_attrib(dag, attribute):
    '''Provides a topological sorting based on a node attribute. The node attribute 'attribute'
    is a number that represents the importance of a node. 
    Lexicographical sorting changes [1,2,13] to [1, 13, 2], therefore we map the distance to lexicographically sorted strings of numbers
    @param: dag The CDSS graph
    @param: attribute The name of the node attribute that should be used for sorting
    @result: topo_order Sorted list of node IDs
    '''
    reciprocal_dist = {n:1/dag.nodes[n][attribute] for n in dag.nodes}
    counter = [str(i) for i in list(range(1, len(reciprocal_dist)+1))]  # list of numbers as strings with the same length as reciprocal_dist
    counter.sort() # sort lexicographical sort
    
    dists = list(set(reciprocal_dist.values()))  # get rid of duplicates
    dists.sort() # sort the reciprocal_dist values
    
    d = dict(zip(dists, counter))
    reciprocal_dist = {i:d[j] for (i,j) in zip(reciprocal_dist.keys(),reciprocal_dist.values())}
    
    topo_order = list(nx.lexicographical_topological_sort(dag, key = lambda x: reciprocal_dist[x]))
    
    return topo_order
    
 
    
def get_longest_path_lengths(dag, rootelement, opt_prio):
    '''Split of the function 'longest_path_lengths'. It does not derive the option_prio, 
    but rather takes it as input. This is good for treatment where you construct the 
    opt_trio from the drawing, but also add a select_multiple for the diagnosis, 
    in order to ensure the proper sorting of the TT. 
    The function gets the longest path (distance) to a node from the rootelement. 
    @result: dictionnary where keys are nodes and values the longest paths
    '''
    dist = dict.fromkeys(dag.nodes, -float('inf')) # keys are nodes, values their longest path length from source   
    dist[rootelement] = 0.001 # set path length of the rootelement to 0.001   
    topo_order = nx.topological_sort(dag) # topological sort for iterating over nodes   
    for n in topo_order:
        for s in dag.successors(n):
            if dist[s] < dist[n] + 1:
                if s in opt_prio:
                    dist[s] = opt_prio[s] + dist[n] + 1
                else:
                    dist[s] = dist[n] + 1
                    
    # the dataloader can result in multiple entries into the flow, therefore there can 
    # be -float('inf') values left. 
    # assign them 0.001
    # all objects with 0.001 will be at the same level with rootelement
    for i in [i for i in dist if dist[i]==-float('inf')]:
        dist[i] = 0.001
    
    return dist


# function to create the subgraph of all nodes lying downstream of 'node'. In the TT flow, it will select the whole graph 
# that comes after a diagnosis-calculate
def create_subgraph(dag, node):
    edges = nx.dfs_successors(dag, node)
    nodes = []
    for k,v in edges.items():
        nodes.extend([k])
        nodes.extend(v)
    return dag.subgraph(nodes)

# function to create a topologically sorted list of the nodes that belong to a diagnosis
def create_objects_sorted(S, df_raw):
    df_S = df_raw.loc[list(S.nodes)] # extract nodes of S from df_raw
    S = list(nx.lexicographical_topological_sort(S)) # topological sort of the subgraph S
    df_S = df_S.reindex(S) # topological sort of the extracted nodes
    objects_sorted = list(df_S.index)
    return objects_sorted

# taking out rhombus objects of the graph
# taken from https://stackoverflow.com/questions/72035535/networkx-contract-adjacent-nodes-in-a-directed-acyclic-graph
def cut_node(arr, key):
    d = {}
    for a, b in arr:
        d.setdefault(a, []).append(b)
    
    if d.get(key) is None:
        return arr
    
    ans = []
    fill_vals = d[key]
    for a, b in arr:
        if a != key:
            if b != key:
                ans.append((a, b))
            else:
                for val in fill_vals:
                    ans.append((a, val))
                    
    return ans


def make_node_relevance(dag, n):
    '''After contraction, the nodes have their own relevance and a 'contraction' attribute that contains
    all the attributes of the contracted nodes, including their relevance. This functions makes a 
    combined relevant expression out of those chunks. 
    @param: dag The graph
    @param: n ID of the node where the relevance should be made
    '''
    nc = [i for i in dag.nodes[n]['contraction']]  # list of nodes that has been contracted into n
    n_relevants = [dag.nodes[n]['contraction'][nc]['relevance'] for nc in nc] # 'relevance' list of the contracted nodes
    n_relevants.append(dag.nodes[n]['relevance']) # append the relevance of the node n (the node we have contracted into)
    n_relevants = [*set(n_relevants)] # drop duplicates
    n_relevants = Or(*n_relevants) # combine all elements with Or
    dag.nodes[n]['relevance'] = n_relevants
    #n_relevants = [*set(n_relevants)] # drop duplicates
    #n_relevants = ['(' + i + ')' for i in n_relevants] # put each element in paranthesis
    #dag.nodes[n]['relevance'] = ' or '.join(n_relevants) # assign the OR join to the relevant
    
    return dag

def make_node_distance_from_root(dag, n):
    '''After contraction, the nodes still have their own distance_from_root, but also a 'contraction' attribute that contains
    all the attributes of the contracted nodes, including their own distance_from_root. This functions takes a the maximum of all those 
    and writes it to the 'distance_from_root' attribute. 
    @param: dag The graph
    @param: n ID of the node where the relevance should be made
    '''
    nc = [i for i in dag.nodes[n]['contraction']]  # list of nodes that has been contracted into n
    n_dist = [dag.nodes[n]['contraction'][nc]['distance_from_root'] for nc in nc] # 'distance_from_root' list of the contracted nodes
    n_dist.append(dag.nodes[n]['distance_from_root']) # append the relevance of the node n (the node we have contracted into)
    n_dist= [*set(n_dist)] # drop duplicates
    n_dist = max(n_dist) # combine all elements with Or
    dag.nodes[n]['distance_from_root'] = n_dist
    #n_relevants = [*set(n_relevants)] # drop duplicates
    #n_relevants = ['(' + i + ')' for i in n_relevants] # put each element in paranthesis
    #dag.nodes[n]['relevance'] = ' or '.join(n_relevants) # assign the OR join to the relevant
    
    return dag


def make_node_distance(dag, n):
    '''After contraction, the nodes have their own longest path distance and a 'contraction' attribute 
    that contains all the attributes of the contracted nodes, including their distance. 
    This functions updates the contracted node distance by the maximum of the dinstances of all 
    contracted nodes. 
    @param: dag The graph
    @param: n ID of the node where the relevance should be made
    '''
    nc = [i for i in dag.nodes[n]['contraction']]  # list of nodes that has been contracted into n
    n_dist = [dag.nodes[n]['contraction'][nc]['distance_from_root'] for nc in nc] # 'distance' list of the contracted nodes
    n_dist.append(dag.nodes[n]['distance_from_root']) # append the original relevant of the node
    dag.nodes[n]['distance_from_root'] = max(n_dist)
    # contraction will still be needed for the 'longest path length' maximum
    del dag.nodes[n]['contraction'] # remove 'contraction' attribute
    
    return n


def get_diagnosis_sorting_id(df_raw, diagnosis_order):
    diagnosis_hierarchy = pd.read_csv(diagnosis_order)
    
    diagnosis_hierarchy['map']= diagnosis_hierarchy['Name'].apply(ch.clean_name) 
    df_raw['map'] = df_raw['value'].astype(str)
    df_raw['map'] = df_raw['map'].apply(ch.clean_name)
    
    m = df_raw['map'].isin(diagnosis_hierarchy['map']) & (df_raw['odk_type']=='diagnosis')
    #dfa = df_raw.loc[m,['id','name']] # slice of df containing the diagnosis (unsorted) 
    
    dfa = df_raw.loc[m,['id','name']].set_index('name') # slice of df containing the diagnosis (unsorted) 
    dfa = dfa.reindex(list(diagnosis_hierarchy['id']))['id'] # that slice, but sorted and 'nan' dropped 
    # (these are diagnosis that exist in dx but not in tt, mostly non-severe ones that have no TT)
    diagnosis_id_hierarchy = list(dfa.dropna())
    return diagnosis_id_hierarchy


def get_diagnosis_sorting_id_from_graph(dag, diagnosis_order):
    diagnosis_hierarchy = pd.read_csv(diagnosis_order)
    
    diagnosis_hierarchy['map']= diagnosis_hierarchy['Name'].apply(ch.clean_name) 
    
    # make dict of style {diagnosis_name:node_id} with information from graph
    # name is already 'cleaned'
    d_from_graph = {ch.clean_name(dag.nodes[n]['content']):n for n in dag.nodes if 'type' in dag.nodes[n].keys() and dag.nodes[n]['type']=='diagnosis'}
    
    # this works also if there is a diagnosis in the hierarchy that does not exist in the diagram -> might be useful if we get a global hierarchy list
    diagnosis_id_hierarchy = [d_from_graph[i] for i in diagnosis_hierarchy['map'] if i in d_from_graph.keys()]

    return diagnosis_id_hierarchy



def get_diagnosis_sorting_id_jupyter(df_raw, diagnosis_order):
    diagnosis_hierarchy = pd.read_csv(diagnosis_order)
    
    diagnosis_hierarchy['map']= diagnosis_hierarchy['Name'].apply(ch.clean_name) 
    df_raw['map'] = df_raw['value'].astype(str)
    df_raw['map'] = df_raw['map'].apply(ch.clean_name)
    
    m = df_raw['map'].isin(diagnosis_hierarchy['map']) & (df_raw['odk_type']=='calculate')
    dfa = df_raw.loc[m,['id','name']].set_index('name') # slice of df containing the diagnosis (unsorted)
    dfa = dfa.groupby(dfa.index).first() # GET RID OF DUPLICATES!!!!!!
    dfa = dfa.reindex(list(diagnosis_hierarchy['id']))['id'] # that slice, but sorted and 'nan' dropped 
    # (these are diagnosis that exist in dx but not in tt, mostly non-severe ones that have no TT)
    diagnosis_id_hierarchy = list(dfa.dropna())
    return diagnosis_id_hierarchy


def add_calculate_selector(dag, n, n_attrib, successors):
    '''Function that creates a select_multiple and select_options objects in front of calculates, that allows to set those
    calculates. This is used for choosing which calculate nodes pointing to the dataloader should
    be switched on or off. 
    It is also used in the TT form to select diagnosis (in case the form is standalone)
    @param dag The graph
    @param n The id of the select_multiple node that will be added to the graph
    @param n_attrib The attributes of that node (relevant, name, type, text)
    @param successors The calculate nodes that get connected to the select_options of the select_multiple. The select_options will have the same as those calculates'''
    dag.add_node(n, **n_attrib) # add select_multiple
    
    option_ids = [i+'s' for i in successors]# make ids for select_options out of successors
    #option_names = [dag.nodes[i]['name']+'_s' for i in successors] # make 'names' for select_options
    #options = [(i+'s',{'name':dag.nodes[i]['name']+'_s', 'type':'select_option', 'group':str(n)}) for i in successors]
    options = [(i+'s',{'name':dag.nodes[i]['name'], 'type':'select_option', 'group':str(n)}) for i in successors]
    #option_attribs = [(i,{'name':dag.nodes[i]['name']+'_s'}) for i in successors]
    #dag.add_nodes_from(option_ids, type='select_option', name=option_names) # add select_options
    dag.add_nodes_from(options) # add select_options
    
    e = [(n, i) for i in option_ids] # edges between select_multiple nodes and the select_options
    dag.add_edges_from(e)
    
    e = list(tuple(zip(option_ids, successors))) # edges between select_options and the calculates
    dag.add_edges_from(e)
    return dag

def add_text_calculate_options(dag, nodename):
    '''Function to add a content-text to select_options created by TRICC right before calculates. 
    These select_options are created to make the TT flow standalone. They allow to assign values
    to elements from DX (dataloader) and to trigger diagnosis. 
    The context is just the context from the successor calculate'''
    a = [i[1] for i in dag.out_edges(nodename)] # ids of select_options
    e = [(a, list(dag.out_edges(a))[0][1]) for a in a] # edges select_option -> calculate
    content = {e[0]:dag.nodes[e[1]]['content'] for e in e}
    
    nx.set_node_attributes(dag, content, 'content')
    
    return dag


def number_calculate_duplicates(dag, df_raw):
    '''Finds duplicates of calculates (several calculates may have the same name in a form) and names them 
    name+nodeID, so that each one of them has a unique name. 
    This is useful so that each of the calculate expressions that has the same the same name 
    can be used as a substitute for longer terms in relevance expressions. 
    In addition this function generates a calculate sink. This is one calculate with the original name and 
    all the calculates, that previously had this name, point to it. Like this, the correct calculate 
    expression for this type will be created during the build of relevance. 
    Calculate nodes cannot be contracted, because it would lead to wrong sorting of the successors of the 
    contracted calculate node
    @param1: dag the graph
    @param2: df_raw the RAW dataframe, with elements from the diagram
    @result: updated graph'''
    for c in df_raw.loc[df_raw['odk_type'].isin(['calculate', 'diagnosis']),'name'].unique():
        if len(df_raw.loc[df_raw['odk_type'].isin(['calculate', 'diagnosis']) & (df_raw['name']==c)])>1: # if there are duplicate calculates
            dfa = df_raw.loc[df_raw['odk_type'].isin(['calculate', 'diagnosis']) & (df_raw['name']==c)] # sub-dataframe with calculate duplicates of name 'c'
            d = dict(zip(dfa['id'], dfa['name'] + '_' + dfa['id']))
            cs = ['calculate' for i in dfa['id']]
            d_type = dict(zip(dfa['id'], cs))
            # need to rename the content as well, because it is used for making the diagnosis_id_hierarchy
            content = dict(zip(dfa['id'], list(dfa['label']+'_'+dfa['id'])))
            nx.set_node_attributes(dag, d, name='name') # d contains attribute that will be named 'name'
            nx.set_node_attributes(dag, content, name='content') # content of the nodes will be the same as before
            nx.set_node_attributes(dag, d_type, name='type') # the nodes of type 'diagnosis' get changed into calculates, the reals diagnosis becomes the 'sink'
            
            nodetype = df_raw.loc[df_raw['name']==c, 'odk_type'].unique()[0] # get odk_type, see if it is 'diagnosis' or 'calculate'
            # adds the 'calculate/diagnosis-sink' for those duplicates (each of them will be pointing to here in addition to the existant edges)
            dag.add_node(c, name = c, type=nodetype, content = list(dfa['label'])[0])  
            
            # add edges
            newedges = [(i,c) for i in d.keys()] # edges between the duplicates and the freshly created calculate sink
            dag.add_edges_from(newedges)
    
    # for calculates only
    #for c in df_raw.loc[df_raw['odk_type']=='calculate','name'].unique():
    #    if len(df_raw.loc[(df_raw['odk_type']=='calculate') & (df_raw['name']==c)])>1: # if there are duplicate calculates
    #        dfa = df_raw.loc[(df_raw['odk_type']=='calculate') & (df_raw['name']==c)] # sub-dataframe with calculate duplicates of name 'c'
    #        d = dict(zip(dfa['id'], dfa['name'] + '_' + dfa['id']))
    #        content = dict(zip(dfa['id'], dfa['label']))
    #        nx.set_node_attributes(dag, d, name='name') # d contains attribute that will be named 'name'
    #        nx.set_node_attributes(dag, content, name='content') # d contains attribute that will be named 'name'
    #        dag.add_node(c, name = c, type='calculate', content=c) # adds the 'calculate-sink' for those duplicates (each of them will be pointing to here in addition to the existant edges)
    #        newedges = [(i,c) for i in d.keys()] # edges between the duplicates and the freshly created calculate sink
    #        dag.add_edges_from(newedges)
    return dag


# Add attributes to nodes
def add_nodeattrib(dag, df_col1, df_col2, attribname):
    '''Adds an attribute to graph nodes; df_col1 is the df-column with the node names, df_col2 is the df-column with the attribute values
    attribname is the name the attribute will have return the graph with the attributes added'''
    attrib = dict(zip(df_col1, df_col2))
    nx.set_node_attributes(dag, attrib, attribname)
    return dag

def switch_nodeattrib(dag, from_attribname, to_attribname, types):
    '''Gets the attribute called 'from_attribname' and writes it into the attribute 'to_attribname', for all nodes where the 'type' 
    attribute is in 'types'. This is used to pull the nodename in Almanach Somalia TT, that is in the content attribute and put it 
    into the 'name' attribute for non rhombus, calculate and diagnosis nodes
    :dag: the graph
    :from_attribname: the name of the attribute where should be pulled
    :to_attribname:  the name of the attribute where the from_attribute content should be written
    :types: all the node types where this should be applied
    '''
    attrib = {n:dag.nodes[n][from_attribname] for n in dag.nodes if dag.nodes[n]['type'] in types}
    nx.set_node_attributes(dag, attrib, to_attribname)
    return dag

# Add attributes to edges
def add_edgeattrib(dag, df_raw, attribname):
    df_edges = df_raw.loc[df_raw['edge']=='1']  # get all arrows from df_raw
    df_edges = df_edges[(df_edges['source']!='') & (df_edges['target']!='')] # remove some artefact objects
    
    attrib = dict(zip(zip(df_edges['source'],df_edges['target']),df_edges['value'].apply(ch.html2plain)))
    nx.set_edge_attributes(dag, attrib, attribname)
    return dag

def build_graph_cdss(df_raw):
    # build a graph
    df_edges = df_raw.loc[df_raw['edge']=='1']  # get all arrows from df_raw
    df_edges = df_edges[(df_edges['source']!='') & (df_edges['target']!='')] # remove some artefact objects
    dag = nx.from_pandas_edgelist(df_edges, source='source', target='target', create_using=nx.DiGraph) # build a graph 
    
    # check if there are loops
    if list(nx.simple_cycles(dag)):
        print('There are loops in the graph!')
    
    # drop image nodes from dag --> why?
    # dag.remove_nodes_from(df_raw[df_raw['style'].str.contains('image',na=False)]['id'])
    
    return dag

# for the script where containers and pages are not connected to their content
# also for connecting select_xxx to their options
def connect_to_parents(dag, df_raw):
    '''This function not only adds edges between existing nodes, it also adds parent nodes. 
    Some parent nodes have not been created yet because the DAG is built based on edges, but there are 
    nodes that have no edges at all. For instance a page that is only pointed to by shortcuts'''
    # drop diagrams.net-page-objects (they do not belong to the drawing); recognised by an empty 'style' column
    df = df_raw.drop(df_raw.loc[df_raw['style']==''].index)
    # drop arrows (which are also children of pages)
    df.drop(df[df['edge']=='1'].index, inplace=True)
    
    n = [i for i in df['id'] if i in list(df['parent'])] # objects in df that appear also in the 'parent' column
    # children that point to their parent and that have NO in_edges (for a page this is the root element only)
    d = {child:parent for (child,parent) in zip(df['id'],df['parent']) if parent in n and len(dag.in_edges(child))==0}
    d = list(zip(d.values(),d.keys())) # convert d to a list of tuples and flip keys <-> values
    dag.add_edges_from(d) # add parent -> child edges to dag
    
    return dag
    

# for the script where containers and pages are not connected to their content
# also for connecting select_xxx to their options
def connect_to_parents_old(dag, df_raw):
    '''Old solution, to be run with the DX jupyter-notebook, it uses different column names. 
    This function not only adds edges between existing nodes, it also adds parent nodes. 
    Some parent nodes have not been created yet because the DAG is built based on edges, but there are 
    nodes that have no edges at all. For instance a page that is only pointed to by shortcuts'''
    # drop diagrams.net-page-objects (they do not belong to the drawing); recognised by an empty 'style' column
    df = df_raw.drop(df_raw.loc[df_raw['style']==''].index)
    # drop arrows (which are also children of pages)
    #df.drop(df[df['style'].str.contains('jettySize')].index, inplace=True)
    df.drop(df[df['edge']=='1'].index, inplace=True)
    n = [i for i in df['id'] if i in list(df['parent'])] # objects in df that appear also in the 'parent' column
    # children that point to their parent and that have NO in_edges (for a page this is the root element only)
    d = {child:parent for (child,parent) in zip(df['id'],df['parent']) if parent in n and len(dag.in_edges(child))==0}
    d = list(zip(d.values(),d.keys())) # convert d to a list of tuples and flip keys <-> values
    dag.add_edges_from(d) # add parent -> child edges to dag
    
    return dag


def connect_to_parents_old_jupyter(dag, df_raw):
    '''Old solution, to be run with the DX jupyter-notebook, it uses different column names. 
    This function not only adds edges between existing nodes, it also adds parent nodes. 
    Some parent nodes have not been created yet because the DAG is built based on edges, but there are 
    nodes that have no edges at all. For instance a page that is only pointed to by shortcuts'''
    # drop diagrams.net-page-objects (they do not belong to the drawing); recognised by an empty 'style' column
    df = df_raw.drop(df_raw.loc[df_raw['style']==''].index)
    # drop arrows (which are also children of pages)
    #df.drop(df[df['style'].str.contains('jettySize')].index, inplace=True)
    df.drop(df[df['edge']=='1'].index, inplace=True)
    n = [i for i in df['id'] if i in list(df['xml-parent'])] # objects in df that appear also in the 'parent' column
    # children that point to their parent and that have NO in_edges (for a page this is the root element only)
    d = {child:parent for (child,parent) in zip(df['id'],df['xml-parent']) if parent in n and len(dag.in_edges(child))==0}
    d = list(zip(d.values(),d.keys())) # convert d to a list of tuples and flip keys <-> values
    dag.add_edges_from(d) # add parent -> child edges to dag
    
    return dag



    
def connect_shortcuts(dag, df_raw):
    '''This function only adds edges between shortcuts (goto) and the node they point to.'''

    df_shortcuts = df_raw.loc[df_raw['odk_type']=='goto',['id','name']]
    df_shortcuts.replace({'name': r'^shortcut_'}, {'name': ''}, regex=True, inplace=True)
    
    exit_nodes = df_raw[df_raw['name'].isin(df_shortcuts['name'].unique())]
    exit_nodes_dict = dict(zip(exit_nodes['name'], exit_nodes['id'])) # nodes the shortcuts point to
        
    df_shortcuts['name'].replace(exit_nodes_dict, inplace = True) # df_shortcuts now represents edges to be added to dag
        
    # add new edges
    shortcut_edges = list(zip(df_shortcuts['id'], df_shortcuts['name']))
    dag.add_edges_from(shortcut_edges)
    return dag

def connect_drop_shortcuts(dag, df_raw):
    '''This function also drops the shortcuts from the DAG. This is actually not necessary 
    and complicated to do. 
    In the future, we will simplify that. The shortcuts will just get as 'expression'
    S.true and it will work'''

    df_shortcuts = df_raw.loc[df_raw['odk_type']=='goto',['id','name']]
    df_shortcuts.replace({'name': r'^shortcut_'}, {'name': ''}, regex=True, inplace=True)
    exit_nodes = df_raw[df_raw['name'].isin(df_shortcuts['name'].unique())]
    exit_nodes_dict = dict(zip(exit_nodes['name'], exit_nodes['id']))
    
    # dictionnary representing the edge towards a shortcut
    node_to_shortcut = [x for x in dag.edges() if x[1] in list(df_shortcuts['id'])]
    node_to_shortcut = dict(zip([x[1] for x in node_to_shortcut], [x[0] for x in node_to_shortcut]))
    
    df_shortcuts['name'].replace(exit_nodes_dict, inplace = True) # replacing name of exit node by its id
    df_shortcuts['id'].replace(node_to_shortcut, inplace = True) # replacing id of shortcut by id of parent node
    # df_shortcuts now represents edges to be added to dag
    
    # drop shortcut nodes in dag
    shortcut_ids = df_raw[df_raw['odk_type']=='goto']['id']
    dag.remove_nodes_from(shortcut_ids)
    
    # add new edges
    shortcut_edges = list(zip(df_shortcuts['id'], df_shortcuts['name']))
    dag.add_edges_from(shortcut_edges)
    return dag

def make_relevance_expression(dag, n, s=True):
    '''Constructs the relevance expression for a node 'n' from the logic expressions of all incoming edges. 
    In case of non-decisive expressions, like notes, the full relevance expressions is built: all
    predecessor nodes, except if they are of types 'select_one yesno', 'select_option' and 'calculate' and 'diagnosis'. 
    'help-message', 'hint-message' type predecessors are ignored.  
    All logic expressions must be written in sympy Symbols. 
    For this to work ,the predecessor nodes must have an existant relevance expression. Therefore prior to applying this function, the nodes need to be 
    topologically sorted
    :param dag: dag is the graph
    :param n: n is the node for which the relevance will be constructed'''
    node_edge_logic = [] # a list to store the combo 'predecessor relevance' AND 'in_edge-expression', each list element is for one predecessor 
    # iterate of predecessors (nodes that have a direct edge to node -> n)
    for pn in dag.predecessors(n):
        #(ignore help and hint fields , later also images)
        if dag.nodes[pn]['type'] not in ['help-message', 'hint-message']:
            
            in_edge_expression = dag.edges[(pn,n)]['logic'] # logic of the edge between 'pn' and n
            # only if predecessors are not of type 'calculate', 'diagnosis', 'select_one yesno' and 'select_option'
            if dag.nodes[pn]['type'] not in ['calculate', 'diagnosis', 'select_one yesno', 'select_option']:
                pn_relevance = dag.nodes[pn]['relevance']  # relevance of predecessor 'pn'
                pne_logic = And(pn_relevance, in_edge_expression) # combine pn_relevance and edge_logic with an AND
            else: 
                pne_logic = in_edge_expression
            node_edge_logic.append(pne_logic) #append node-edge-logic combo for pn->n to a list
  
    relevance = build_node_relevance(dag, n, node_edge_logic, s)
    
    if relevance!=False:
        dag.nodes[n]['relevance']=relevance # write relevance to node 'n' as attribute
    else: 
        dag.nodes[n]['relevance']=S.true # that means that there are no incoming edges, so `relevance = []`, so the relevance must be True

    return dag


def make_full_relevance_expression(dag, n, s=True):
    '''Constructs the FULL relevance expression for a node 'n' from the logic expressions of all incoming edges AND the relevance expressions of all
    predecessor nodes, except if they are of types 'select_one yesno', 'select_option' and 'calculate' and 'diagnosis'. 
    'help-message', 'hint-message' type predecessors are ignored.  
    All logic expressions must be written in sympy Symbols. 
    For this to work ,the predecessor nodes must have an existant relevance expression. Therefore prior to applying this function, the nodes need to be 
    topologically sorted
    :param dag: dag is the graph
    :param n: n is the node for which the relevance will be constructed'''
    node_edge_logic = [] # a list to store the combo 'predecessor relevance' AND 'in_edge-expression', each list element is for predecessor 
    # iterate of predecessors (nodes that have a direct edge to node -> n)
    for pn in dag.predecessors(n):
        #(ignore help and hint fields , later also images)
        if dag.nodes[pn]['type'] not in ['help-message', 'hint-message']:
            
            in_edge_expression = dag.edges[(pn,n)]['logic'] # logic of the edge between 'pn' and n
            # only if predecessors are not of type 'calculate', 'diagnosis'
            if dag.nodes[pn]['type'] not in ['calculate', 'diagnosis']:
                pn_relevance = dag.nodes[pn]['relevance']  # relevance of predecessor 'pn'
                pne_logic = simplify(And(pn_relevance, in_edge_expression)) # combine pn_relevance and edge_logic with an AND
            else: 
                pne_logic = in_edge_expression
            node_edge_logic.append(pne_logic) #append node-edge-logic combo for pn->n to a list
    
    relevance = build_node_relevance(dag, n, node_edge_logic, s)

    # relevance might not exist, for initial nodes for instance
    if relevance!=False:
        dag.nodes[n]['relevance']=relevance # write relevance to node 'n' as attribute
    else: 
        dag.nodes[n]['relevance']=S.true

    return dag
    

def build_node_relevance(dag, n, node_edge_logic, s=True):
    '''Writes the logical expression for the relevance of a node. For counters the global expression is not made, because here the items from node_edge_logic 
    must be converted from booleans to integers and then summed up. This is dealth with when moving to ODK. 
    @ dag: the graph we work on
    @ n: the node for which we write the logical expression
    @ node_edge_logic: the list of singular expressions for each incoming edge into n
    @ s: boolean, wheather the expression should be simplified to be shorter and quicker to execute (if True, TRICC is slowed down)
    @ return: the logical expression for n'''
    if dag.nodes[n]['type']!='count':
        if s:
            # print('Simplifying relevance expression of node', n, 'Name:', dag.nodes[n]['name'])
            relevance = simplify(Or(*node_edge_logic)) # combine node-edge-logic combos of all pn->n with OR
        else: 
            relevance = Or(*node_edge_logic)
    else: # for counters, just keep the list. When converting sympy into odk, it will become number(...)+number(...), not implemented yet
        print('count node', n)
        relevance = node_edge_logic 
    
    return relevance


def write_node_relevance(dag):
    '''Writes the calculated relevance into the nodes of a dag'''
    for n in nx.topological_sort(dag):
        # solution for relevance being only based on the direct predecessors:
        # dag = make_relevance_expression(dag, n)
        # solution for relevance being the full relevance, with all ascendants, up to the root
        dag = make_full_relevance_expression(dag, n)
    return dag
    
    
def get_node_ids(candidate, dag):
    '''Function to retrieve a list of nodes that have the type-attribute candidate[0] and the name-attribute candidate[1]
    @result is a list of node_ids'''
    # nodes of that candidate
    nodes = [n for n in dag.nodes if dag.nodes[n]['type'] == candidate[0] and dag.nodes[n]['name'] == candidate[1]] 
    
    return nodes

def contract_duplicates(dag, contract_types):
    ''' Function to contract duplicates in a graph. Duplicates are defined as nodes that have the same type and name at the same time. 
    The function attempts to contract all occurences into one single node by trying all combinations of the occurence of this node. 
    If a contraction  would create cycle, it is aborted and further combinations are tried
    @param dag is the graph
    @param contract_types is the types that should be contracted. Not all types can or should be  contracted. One examply is rhombus
    @result dag is the graph with the nodes contracted'''
    
    # identify all duplicates in (name, type) pairs
    candidates = list(set([(dag.nodes[n]['type'], dag.nodes[n]['name']) for n in dag.nodes if dag.nodes[n]['type'] in contract_types]))

    # list of lists of nodes that qualify  for contraction
    candidate_duplicates = [get_node_ids(n, dag) for n in candidates if len(get_node_ids(n, dag))>1] 

    a = len(dag.nodes) #initial amount of nodes in  the dag

    for i in candidate_duplicates:
        for j, k in combinations(i, 2):
                    if j in dag.nodes and k in dag.nodes:
                        # check if contraction would create a loop
                        dag2 = nx.contracted_nodes(dag, j, k, self_loops=False) # merge k into j
                        if nx.is_directed_acyclic_graph(dag2):
                            dag = dag2                      
                        else:
                            print('For the combination:', dag.nodes[j]['type'], ' -' , dag.nodes[j]['name'], '\n the node', k, 'did not contract into', j, 'because it would have created a cycle')
    k = a - len(dag.nodes) # amount of contracted nodes
    print('In total,', k, 'nodes have been contracted.')
    return dag


def push_down_relevance(dag,n):
    '''This function adds the relevance of the node 'n' to the successors of that node where no decision is 
    taken (all except select_one yesno and select_options) 
    or where the relevance is substituted by a different expression (calculate or diagnosis fields)
    The relevance is appended to the already existing relevance expression with an And 
    The pushing stops until the graph reaches a node of type select_one yesno, a select_option, or
    the predecessor of a calculate/diagnosis
    This function is used to update the relevance of the successors of contracted nodes. ´
    ''' 
    
    # make a subgraph from n and all of its descendants
    # get all descendants of n
    s_nodes = [n for n in nx.descendants(dag,n)]
    s_nodes.append(n) # add the node n to its descendants
    sdag = dag.subgraph(s_nodes) #  extract a subgraph with n being the rootelement
    sdag = sdag.copy(as_view=False) # make a real, editable copy of the subgraph
    
    # edges that will have to be deleted 
    # (where parent node is select-one yesno or select_option) 
    # or where child node is a 'calculate' or a 'diagnosis'
    breakedges = [e for e in sdag.edges if sdag.nodes[e[0]]['type'] in ['select_one yesno', 'select_option'] or sdag.nodes[e[1]]['type'] in ['calculate', 'diagnosis']]
    
    sdag.remove_edges_from(breakedges) # remove the breakedges from the subgraph
    # get a list of all nodes that will inherit the relevance of 'n':¨
    relevance_inheritors = [n for n in nx.descendants(sdag, n)]
    n_relevance = dag.nodes[n]['relevance']
    # get relevance on the node 'n', that should be pushed down to the selected succewssors
    
    # update relevance of the selected successors of n:
    for n in relevance_inheritors:
        dag.nodes[n]['relevance'] = And(dag.nodes[n]['relevance'], n_relevance)
        
    return dag
        

def substitute_group_relevance(n, dag):
    '''subsitutes the relevance expression of a group by S.true (for children of groups, they do not need 
    the relevance expression repeated inside their own relevance)
    :param n: the node in which you want to erase the relevance of the group it belongs to
    :param dag: the graph
    '''
    group_id = dag.nodes[n]['group']
    dag.nodes[n]['relevance'] = dag.nodes[n]['relevance'].subs(dag.nodes[group_id]['relevance'], S.true)
    
    return dag
    
def make_help_attributes(dag):
    '''This function is writing the content of help and hint nodes into the corresponding attribute of the nodes
    that the help/hint nodes point to
    :param dag: the graph
    '''
    for t in ['help-message', 'hint-message']:
        # works only if a help message is pointing to 1 node only
        d = {list(dag.successors(n))[0]:dag.nodes[n]['content'] for n in dag.nodes if dag.nodes[n]['type'] in [t]} 
        nx.set_node_attributes(dag, d, name=t)
        
    return  dag


def extract_images(dag, df_raw, mediafolder):
    '''This function extracts the images, stores them in the correct folder and writes the image name as an attribute to the node the image points to. 
    :param dag: the graph
    '''
    # get all images from df_raw (image content is not in the graph, to keep it light)
    imagenodes = df_raw.loc[df_raw['style'].str.contains('image=data:image/',na=False), 'id'].to_list()
    
    os.makedirs(mediafolder, exist_ok=True)  # recursively create mediafolder, do nothing if it exists
    
    for i in imagenodes:
        for j in dag.successors(i):
            # image metadata + data
            image = df_raw.loc[df_raw['id']==i, 'style'].to_list()[0]
            
            # extract type of image (jpeg, png,...)
            img_type = re.search('image=data:image/(.+?),',image).group(1) # extract image data from 'style' column using regex
            # extract image itself
            img_data=re.search('image=data:image/.+,(.+?);',image).group(1) # extract image data from 'style' column using regex
            
            # write imagename to node attribute `image::en`
            dag.nodes[j]['image::en']=i + '.' + img_type
            
            # store file to disk
            with open(mediafolder+i+'.'+img_type, "wb") as fh:
                fh.write(base64.decodebytes(img_data.encode('ascii'))) # encode image into ascii (binary) and save
        
    return  dag
    

def rename_duplicates(dag,types):
    '''Grabs all (type,name) combos where the type is in 'types' and where duplicates occur. 
    Add to the name of those nodes the node-id
    '''
    # get all name,type combos
    candidates = list(set([(dag.nodes[n]['type'], dag.nodes[n]['name']) for n in dag.nodes if dag.nodes[n]['type'] in types]))
    
    # list of lists of nodes that qualify  for contraction
    candidate_duplicates = [get_node_ids(n, dag) for n in candidates if len(get_node_ids(n, dag))>1] 

    for i in candidate_duplicates:
        for j in i:
            dag.nodes[j]['name'] = dag.nodes[j]['name'] + '_' + j

    return dag


def sort_subgraph(dag, node, opt_prio):
    '''Generate a cdss sorted list of nodes that belong to a diagnosis, returns a list'''
    diagnosis_nodes = list(nx.descendants(dag, node))
    diagnosis_nodes.append(node)
    d_graph = dag.subgraph(diagnosis_nodes) # subgraph for a particular diagnosis
    diagnosis_nodes_sorted = get_topo_sort_cdss(d_graph, node, opt_prio) # topological sort of that graph

    return diagnosis_nodes_sorted


def make_sorted_nodes_list(dag, diagnosis_id_hierarchy, opt_prio):
    '''Generates a list with CDSS-sorted nodes for each diagnosis node. It makes a subgraph
    for each diagnosis, sorts it and writes the order in a list. That list is then written into
    a list of lists where each list represents a diagnosis, the list of lists is sorted according to diagnosis hierarchy. '''
    d = [sort_subgraph(dag, i, opt_prio) for i in diagnosis_id_hierarchy] # list expressed as node ids
    
    return d

def map_node_to_name_type(d, dag):
    '''maps all nodes in a list of lists to tuples of the form (name, type)'''
    d_out = []
    for i in d:
        i_new = [(dag.nodes[n]['name'], dag.nodes[n]['type']) for n in i]
        d_out.append(i_new)
        
    return d_out

def make_linear_diagnosis_graph(d):
    '''Make a second graph in which every diagnosis is disconnected and its successors are linear aligned according to the
    sorting of nodes for this diagnosis. 
    @d: the dictionary with all diagnosis nodes as keys and the values being a list with subsequent nodes for that diagnosis
    @return: the linear graph'''
    edges = [list(zip(i[:-1], i[1:])) for i in d] # for each diagnosis make tuples of adjacent nodes
    edges = sum(edges, [])
    graph = nx.from_edgelist(edges, nx.DiGraph)
    
    return graph

def pop_rhombus(l, dag):
    '''in  a list `l` of nodes for a diagnosis, remove those of type `rhombus` '''
    
    new_l = []
    for n in l:
        if dag.nodes[n]['type']!='rhombus':
            new_l.append(n)
    
    return new_l

